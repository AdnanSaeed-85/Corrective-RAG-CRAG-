{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a4dcf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from CONFIG import GROQ_MODEL, OPENAI_EMBEDDED_MODEL\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "275210d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "181ce09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL loaded\n",
    "\n",
    "embedded_model = OpenAIEmbeddings(model=OPENAI_EMBEDDED_MODEL)\n",
    "llm = ChatGroq(model=GROQ_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c1e17b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF has 8 pages\n"
     ]
    }
   ],
   "source": [
    "# PDF loading\n",
    "\n",
    "pdf = PyPDFLoader(file_path='A:\\AI_Projects_Practice\\CRAG\\The_Evolution_of_AI_in_Dubai.pdf')\n",
    "pdf_loaded = pdf.load()\n",
    "print(f\"PDF has {len(pdf_loaded)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc4257d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks are 24\n"
     ]
    }
   ],
   "source": [
    "# Chunking\n",
    "\n",
    "chunks = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=100).split_documents(pdf_loaded)\n",
    "print(f\"Total chunks are {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44cbb7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stored in vector database (FAISS)\n",
    "\n",
    "vectore_storage = FAISS.from_documents(chunks, embedded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed8b5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieved based on similarity (k=2)\n",
    "\n",
    "retriever = vectore_storage.as_retriever(serach_type='similarity', serach_kwargs={'k': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ca0d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class state(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    doc: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1340afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieved_str(state: state) -> str:\n",
    "    q = state['question']\n",
    "    return {'question': retriever.invoke(q)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25542f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Answer only from the context. If not in context, say you don't know.\"),\n",
    "        (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def generate(state):\n",
    "    context = \"\\n\\n\".join(d.page_content for d in state[\"doc\"])\n",
    "    out = (prompt | llm).invoke({\"question\": state[\"question\"], \"context\": context})\n",
    "    return {\"answer\": out.content}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
